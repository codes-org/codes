# Measure the performance of MPI_Allgather()
# By Scott Pakin <pakin@lanl.gov>
#
# N.B. Requires the c_mpi backend.
Require language version "1.5".
# Parse the command line.
numwords is "Message size (words)" and comes from "--msgsize" or "-s" with default 28825K.
reps is "Number of repetitions" and comes from "--reps" or "-r" with default 100.
computetime is "Computation time (ms)" and comes from "--compute" or "-c" with default 129.

# Allocate a send buffer and a receive buffer.
Task 0 multicasts a numwords*num_tasks word message from buffer 0 to all other tasks.
Task 0 multicasts a numwords*num_tasks word message from buffer 1 to all other tasks.

# Measure the performance of MPI_Allreduce().
Task 0 resets its counters then
for reps repetitions {
    all tasks COMPUTES FOR computetime MILLISECONDS then
    all tasks backend execute "
        MPI_Allreduce([MESSAGE BUFFER 0], [MESSAGE BUFFER 1], (int)" and numwords and ",
                MPI_INT, MPI_SUM, MPI_COMM_WORLD);
        " then
    all tasks backend execute "
        MPI_Allreduce([MESSAGE BUFFER 0], [MESSAGE BUFFER 1], (int)" and numwords and ",
                MPI_INT, MPI_SUM, MPI_COMM_WORLD);
        "
} then
task 0 logs elapsed_usecs/1000 as "Elapse time (ms)".
